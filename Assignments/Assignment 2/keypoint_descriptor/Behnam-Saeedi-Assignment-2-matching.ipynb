{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USE pretrained network to output keypoint's description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import PIL\n",
    "import random\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import torch\n",
    "import torch.nn.init\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "from copy import deepcopy, copy\n",
    "from config_profile import args\n",
    "from Utils import cv2_scale36, cv2_scale, np_reshape, np_reshape64\n",
    "from munkres import Munkres\n",
    "from descriptor_CNN3 import DesNet\n",
    "\n",
    "Debug = False\n",
    "\n",
    "model = DesNet()\n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "weight_path = \"checkpoint_b.pth\"\n",
    "trained_weight = torch.load(weight_path)\n",
    "model.load_state_dict(trained_weight['state_dict'])\n",
    "\n",
    "# load patches\n",
    "patches_a_dir = \"../keypoint_detector/patches-a.pt\"\n",
    "patches_i_dir = \"../keypoint_detector/patches-i.pt\"\n",
    "patches_q_dir = \"../keypoint_detector/patches-q.pt\"\n",
    "patches_a = torch.load(patches_a_dir)\n",
    "patches_i = torch.load(patches_i_dir)\n",
    "patches_q = torch.load(patches_q_dir)\n",
    "\n",
    "if Debug:\n",
    "    print(patches_a.shape)\n",
    "    print(patches_i.shape)\n",
    "    print(patches_q.shape)\n",
    "patches_a =  patches_a.view(-1, 1, 32, 32).cuda()\n",
    "patches_i =  patches_i.view(-1, 1, 32, 32).cuda()\n",
    "patches_q =  patches_q.view(-1, 1, 32, 32).cuda()\n",
    "\n",
    "#description = model(patches)\n",
    "with torch.no_grad():\n",
    "    description_a = model(patches_a)\n",
    "    description_i = model(patches_i)\n",
    "    description_q = model(patches_q)\n",
    "\n",
    "description_a = description_a.view(-1, 30, 128)\n",
    "description_i = description_i.view(-1, 30, 128)\n",
    "description_q = description_q.view(-1, 30, 128)\n",
    "\n",
    "torch.save(description_a, \"Description.pt\")\n",
    "\n",
    "if Debug:\n",
    "    print(description_a.shape)\n",
    "    print(description_i.shape)\n",
    "    print(description_q.shape)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Debug = False\n",
    "similarity_matrix_one_to_one = np.zeros((35,140))\n",
    "if Debug:\n",
    "    print(description_q[0].shape)\n",
    "    print(description_i[0].shape)\n",
    "hungarian = Munkres()\n",
    "for i in range(0,35):\n",
    "    top = 0\n",
    "    for j in range(0,140):\n",
    "        dist = np.zeros((30,30))\n",
    "        for k in range(0,30):\n",
    "            for l in range(0,30):\n",
    "                dist[k][l] = np.linalg.norm(np.subtract(description_q[i][k].cpu().numpy(), description_i[j][l].cpu().numpy()))\n",
    "        cost_indecies = hungarian.compute(np.copy(dist))\n",
    "        tmp = np.zeros(len(cost_indecies))\n",
    "        for k in range(0,len(cost_indecies)):\n",
    "            tmp[k] = np.exp(-(dist[cost_indecies[k][0]][cost_indecies[k][1]]))\n",
    "        similarity_matrix_one_to_one[i][j]=tmp.sum()\n",
    "        if(top < similarity_matrix_one_to_one[i][j]):\n",
    "            top = similarity_matrix_one_to_one[i][j]\n",
    "            if Debug:\n",
    "                print((i,j))\n",
    "if Debug:\n",
    "    print(similarity_matrix_one_to_one)\n",
    "# Check point: saving the tensor to prevent re computing it\n",
    "save = False\n",
    "if save:\n",
    "    print(\"Saving a checkpoint...\")\n",
    "    torch.save(similarity_matrix_one_to_one, \"checkpoint-1-to-1.pt\")\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading one to one tensor from file\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# start from here to reload the tensor\n",
    "Debug = False\n",
    "print(\"Loading one to one tensor from file\")\n",
    "similarity_matrix_one_to_one = torch.load(\"checkpoint-1-to-1.pt\")\n",
    "if Debug:\n",
    "    print(similarity_matrix_one_to_one.shape)\n",
    "    print(similarity_matrix_one_to_one)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35, 140])\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#Tensor Re-saving\n",
    "similarity_matrix_one_to_one_new = torch.Tensor(similarity_matrix_one_to_one)\n",
    "print(similarity_matrix_one_to_one_new.shape)\n",
    "torch.save(similarity_matrix_one_to_one_new, \"checkpoint-1-to-1-tensor.pt\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Debug = False\n",
    "similarity_matrix_many_to_many = np.zeros((35,140))\n",
    "threshold = 0.1\n",
    "if Debug:\n",
    "    print(description_q.shape)\n",
    "    print(description_i.shape)\n",
    "for i in range(0,35):\n",
    "    top = [np.NINF,(0,0)]\n",
    "    for j in range(0,140):\n",
    "        dist = np.zeros(30)\n",
    "        for k in range(0,30):\n",
    "            tmp = np.zeros(30)\n",
    "            for l in range(k,30):\n",
    "                query = description_q[i][k].cpu().numpy()\n",
    "                image = description_i[j][l].cpu().numpy()\n",
    "                tmp[k] = np.sum(np.absolute(np.subtract(query,image)))\n",
    "            dist[k] = np.linalg.norm(tmp)\n",
    "        s = np.zeros(30)\n",
    "        x = np.zeros(30)\n",
    "        x_s = np.zeros(30)\n",
    "        for k in range (0,30):\n",
    "            s[k] = np.exp(-(dist[k]))\n",
    "        lamda = np.sqrt(1 / np.dot(np.transpose(s), s))\n",
    "        norm = np.linalg.norm(s,axis=0)\n",
    "        x = np.true_divide(s, norm)\n",
    "        x_s = np.copy(x)\n",
    "        x_s[x_s > threshold] = 1\n",
    "        x_s[x_s < threshold] = 0\n",
    "        a = np.dot(np.transpose(s), x_s)\n",
    "        b = lamda * (np.dot(np.transpose(x_s), x_s) - 1)\n",
    "        similarity_matrix_many_to_many[i][j]= a - b\n",
    "        if Debug:\n",
    "            print(\"lamda: \"+str(lamda))\n",
    "            print(\"norm: \"+str(norm))\n",
    "            print(\"s: \"+str(s))\n",
    "            print(\"x: \"+str(x))\n",
    "            print(\"x_s: \"+str(x_s))\n",
    "            print(\"a: \"+str(a))\n",
    "            print(\"b: \"+str(b))\n",
    "            print(\"Similarity: \" + str(similarity_matrix_many_to_many[i][j]))\n",
    "        if (similarity_matrix_many_to_many[i][j] > top[0]):\n",
    "            top = [similarity_matrix_many_to_many[i][j],(i,j)]\n",
    "            print(str(top[0]) + \": \" + str(top[1]))\n",
    "    print(top)\n",
    "    print(\"_____\")\n",
    "save = False\n",
    "if save:\n",
    "    print(\"Saving a checkpoint...\")\n",
    "    torch.save(similarity_matrix_many_to_many, \"checkpoint-many-to-many.pt\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading many to many tensor\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Import many to many matching here and skip last step\n",
    "Debug = False\n",
    "print (\"Loading many to many tensor\")\n",
    "similarity_matrix_many_to_many = torch.load(\"checkpoint-many-to-many.pt\")\n",
    "if Debug:\n",
    "    print(similarity_matrix_many_to_many.shape)\n",
    "    print(similarity_matrix_many_to_many)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35, 140])\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#Tensor Re-saving\n",
    "similarity_matrix_many_to_many_new = torch.Tensor(similarity_matrix_many_to_many)\n",
    "print(similarity_matrix_many_to_many_new.shape)\n",
    "torch.save(similarity_matrix_many_to_many_new, \"checkpoint-many-to-many-tensor.pt\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall = $\\frac{TP(\\hat{X})}{4}$ and Precision= $\\frac{TP(\\hat{X})}{ k\\in {1..4}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ground truth\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Load in ground truth\n",
    "Debug = False\n",
    "print(\"Loading ground truth\")\n",
    "y =  np.subtract(np.array([[1, 1], [1, 2], [1, 3], [1, 4], [2, 5], [2, 6], [2, 7], [2, 8], [3, 9], [3, 10], [3, 11], [3, 12], [4, 13], [4, 14], [4, 15], [4, 16], [5, 17], [5, 18], [5, 19], [5, 20], [6, 21], [6, 22], [6, 23], [6, 24], [7, 25], [7, 26], [7, 27], [7, 28], [8, 29], [8, 30], [8, 31], [8, 32], [9, 33], [9, 34], [9, 35], [9, 36], [10, 37], [10, 38], [10, 39], [10, 40], [11, 41], [11, 42], [11, 43], [11, 44], [12, 45], [12, 46], [12, 47], [12, 48], [13, 49], [13, 50], [13, 51], [13, 52], [14, 53], [14, 54], [14, 55], [14, 56], [15, 57], [15, 58], [15, 59], [15, 60], [16, 61], [16, 62], [16, 63], [16, 64], [17, 65], [17, 66], [17, 67], [17, 68], [18, 69], [18, 70], [18, 71], [18, 72], [19, 73], [19, 74], [19, 75], [19, 76], [20, 77], [20, 78], [20, 79], [20, 80], [21, 81], [21, 82], [21, 83], [21, 84], [22, 85], [22, 86], [22, 87], [22, 88], [23, 89], [23, 90], [23, 91], [23, 92], [24, 93], [24, 94], [24, 95], [24, 96], [25, 97], [25, 98], [25, 99], [25, 100], [26, 101], [26, 102], [26, 103], [26, 104], [27, 105], [27, 106], [27, 107], [27, 108], [28, 109], [28, 110], [28, 111], [28, 112], [29, 113], [29, 114], [29, 115], [29, 116], [30, 117], [30, 118], [30, 119], [30, 120], [31, 121], [31, 122], [31, 123], [31, 124], [32, 125], [32, 126], [32, 127], [32, 128], [33, 129], [33, 130], [33, 131], [33, 132], [34, 133], [34, 134], [34, 135], [34, 136], [35, 137], [35, 138], [35, 139], [35, 140]]),1)\n",
    "if Debug:\n",
    "    print(y)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 to 1 Precision with k = 1:  0.42857142857142855\n",
      "1 to 1 Recall with k = 1: 0.10714285714285714\n",
      "1 to 1 Precision with k = 2:  0.5285714285714286\n",
      "1 to 1 Recall with k = 2: 0.2642857142857143\n",
      "1 to 1 Precision with k = 3:  0.6571428571428571\n",
      "1 to 1 Recall with k = 3: 0.4928571428571429\n",
      "1 to 1 Precision with k = 4:  0.75\n",
      "1 to 1 Recall with k = 4: 0.75\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Computing Precision/recall for one to one matching\n",
    "Debug = False\n",
    "precision_1_to_1 = np.zeros((4,similarity_matrix_one_to_one.shape[0]))\n",
    "recall_1_to_1 = np.zeros((4,similarity_matrix_one_to_one.shape[0]))\n",
    "for k in range(1,5):\n",
    "    for i in range(0,similarity_matrix_one_to_one.shape[0]):\n",
    "        y_hat = (-similarity_matrix_one_to_one[i]).argsort()[:k]\n",
    "        hits = 0\n",
    "        for j in range(0,k):\n",
    "            index = 4 * i + j\n",
    "            if y[index][1] in y_hat:\n",
    "                hits += 1\n",
    "        if Debug:\n",
    "            y_p = [y[4 * i][1],y[4 * i + 1][1],y[4 * i + 2][1],y[4 * i + 3][1]]\n",
    "            print(\"k: \", k)\n",
    "            print(\"y: \"+str(y_p))\n",
    "            print(\"y_hat: \" + str(y_hat))\n",
    "            print(\"Hits: \"+str(hits))\n",
    "        precision_1_to_1[k-1][i] = hits/k\n",
    "        recall_1_to_1[k-1][i] = hits/4\n",
    "    print (\"1 to 1 Precision with k = \"+str(k)+\": \",np.sum(precision_1_to_1[k-1])/similarity_matrix_one_to_one.shape[0])\n",
    "    print(\"1 to 1 Recall with k = \"+str(k)+\":\", np.sum(recall_1_to_1[k-1])/similarity_matrix_one_to_one.shape[0])\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Many to Many Precision with k = 1:  0.17142857142857143\n",
      "Many to Many Recall with k = 1: 0.04285714285714286\n",
      "Many to Many Precision with k = 2:  0.21428571428571427\n",
      "Many to Many Recall with k = 2: 0.10714285714285714\n",
      "Many to Many Precision with k = 3:  0.27619047619047615\n",
      "Many to Many Recall with k = 3: 0.20714285714285716\n",
      "Many to Many Precision with k = 4:  0.2714285714285714\n",
      "Many to Many Recall with k = 4: 0.2714285714285714\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Computing Precision/recall for many to many matching\n",
    "Debug = False\n",
    "count = 4\n",
    "precision_many_to_many = np.zeros((4,35))\n",
    "recall_many_to_many = np.zeros((4,35))\n",
    "for k in range(1,5):\n",
    "    for i in range(0,similarity_matrix_many_to_many.shape[0]):\n",
    "        y_hat = (-similarity_matrix_many_to_many[i]).argsort()[:k]\n",
    "        hits = 0\n",
    "        for j in range(0,k):\n",
    "            index = 4 * i + j\n",
    "            if y[index][1] in y_hat:\n",
    "                hits += 1\n",
    "        if Debug:\n",
    "            y_p = [y[4 * i][1],y[4 * i + 1][1],y[4 * i + 2][1],y[4 * i + 3][1]]\n",
    "            print(\"k: \", k)\n",
    "            print(\"y: \"+str(y_p))\n",
    "            print(\"y_hat: \" + str(y_hat))\n",
    "            print(\"Hits: \"+str(hits))\n",
    "        precision_many_to_many[k-1][i] = hits/k\n",
    "        recall_many_to_many[k-1][i] = hits/4\n",
    "    print (\"Many to Many Precision with k = \"+str(k)+\": \",np.sum(precision_many_to_many[k-1])/similarity_matrix_many_to_many.shape[0])\n",
    "    print(\"Many to Many Recall with k = \"+str(k)+\":\", np.sum(recall_many_to_many[k-1])/similarity_matrix_many_to_many.shape[0])\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
