{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keypoint Detection Solution\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# load packages\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import re\n",
    "%matplotlib inline\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Initiate SIFT detector\n",
    "sift = cv2.xfeatures2d.SIFT_create(30)\n",
    "surf = cv2.xfeatures2d.SURF_create(300)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def getPatches(kps, img, size=32, num=500):\n",
    "    res = torch.zeros(num, 1, size, size)\n",
    "    if type(img) is np.ndarray:\n",
    "        img = torch.from_numpy(img)\n",
    "    h, w = img.shape      # note: for image, the x direction is the verticle, y-direction is the horizontal...\n",
    "    for i in range(num):\n",
    "        cx, cy = kps[i]\n",
    "        cx, cy = int(cx), int(cy)\n",
    "        dd = int(size/2)\n",
    "        xmin, xmax = max(0, cx - dd), min(w, cx + dd ) - 1\n",
    "        ymin, ymax = max(0, cy - dd), min(h, cy + dd ) - 1 \n",
    "        \n",
    "        xmin_res, xmax_res = dd - min(dd,cx), dd + min(dd, w - cx)-1\n",
    "        ymin_res, ymax_res = dd - min(dd,cy), dd + min(dd, h - cy)-1\n",
    "\n",
    "        res[i, 0, ymin_res: ymax_res, xmin_res: xmax_res] = img[ymin: ymax, xmin: xmax]\n",
    "    return res\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.JPG\n",
      "q1.JPG\n",
      "2.JPG\n",
      "q2.JPG\n",
      "3.JPG\n",
      "q3.JPG\n",
      "4.JPG\n",
      "q4.JPG\n",
      "5.JPG\n",
      "q5.JPG\n",
      "6.JPG\n",
      "q6.JPG\n",
      "7.JPG\n",
      "q7.JPG\n",
      "8.JPG\n",
      "q8.JPG\n",
      "9.JPG\n",
      "q9.JPG\n",
      "10.JPG\n",
      "q10.JPG\n",
      "11.JPG\n",
      "q11.JPG\n",
      "12.JPG\n",
      "q12.JPG\n",
      "13.JPG\n",
      "q13.JPG\n",
      "14.JPG\n",
      "q14.JPG\n",
      "15.JPG\n",
      "q15.JPG\n",
      "16.JPG\n",
      "q16.JPG\n",
      "17.JPG\n",
      "q17.JPG\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-29eaafc7ae0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mkps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msurf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mkeypoints_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpt\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkps_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeypoints_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m## extract patches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-29eaafc7ae0f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mkps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msurf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mkeypoints_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpt\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkps_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeypoints_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m## extract patches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#img_dir = \"../image_retrieval/images\"\n",
    "#img_dir = \"../image_retrieval/query\"\n",
    "img_dir = \"../image_retrieval/all\"\n",
    "kps_num = 30\n",
    "patch_size = 32\n",
    "#number_of_images = 140\n",
    "#number_of_images = 35\n",
    "number_of_images = 175\n",
    "res = torch.zeros(number_of_images, kps_num, 2)\n",
    "patches = torch.zeros(number_of_images, kps_num, 1, patch_size, patch_size)\n",
    "if os.path.exists(img_dir):\n",
    "    if os.listdir(img_dir) is []:\n",
    "        print(\"No images!\")\n",
    "        exit(0)\n",
    "    num_img = len(os.listdir(img_dir))\n",
    "    idx = 0\n",
    "    sorted_listdir = sorted(os.listdir(img_dir), key=lambda e: [int(s) for s in re.split('[q.]', e) if s.isdigit()])\n",
    "    for img in sorted_listdir:\n",
    "        print(img)\n",
    "        if not img.endswith(\"JPG\"):\n",
    "            continue\n",
    "        image_dir = os.path.join(img_dir, img)\n",
    "        image = cv2.imread(image_dir)\n",
    "        img= cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        ## find the keypoints and descriptors with SIFT\n",
    "        if (image_dir != \"../image_retrieval/all\\q17.JPG\"):\n",
    "            kps, des = sift.detectAndCompute(img, None)\n",
    "            keypoints_img = [kps[a].pt for a in range(kps_num)] \n",
    "            res[idx] = torch.FloatTensor(keypoints_img)\n",
    "        else:\n",
    "            kps, des = surf.detectAndCompute(img, None)\n",
    "            keypoints_img = [kps[a].pt for a in range(kps_num)] \n",
    "            res[idx] = torch.FloatTensor(keypoints_img)\n",
    "        ## extract patches\n",
    "        patches[idx] = getPatches(keypoints_img, img, size=patch_size, num=kps_num)\n",
    "        idx += 1\n",
    "else:\n",
    "    print(\"image folder not exists!\")\n",
    "    exit(0)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.shape)\n",
    "print(patches.shape)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save tensors\n",
    "#output_dir_kps = \"keypoints-i.pt\"\n",
    "#output_dir_patches = \"patches-i.pt\"\n",
    "#output_dir_kps = \"keypoints-q.pt\"\n",
    "#output_dir_patches = \"patches-q.pt\"\n",
    "output_dir_kps = \"keypoints-a.pt\"\n",
    "output_dir_patches = \"patches-a.pt\"\n",
    "torch.save(res, output_dir_kps)\n",
    "torch.save(patches, output_dir_patches)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
